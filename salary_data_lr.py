# -*- coding: utf-8 -*-
"""salary_data_lr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMSbN6MbqS7icgZ7w6KPWqvDMcYHAiVD
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

salary_df=pd.read_csv('/content/drive/MyDrive/Salary_Data.csv')

salary_df

salary_df.info()

salary_df.describe()

salary_df.shape

salary_df.isnull().sum()

salary_df.head(10)

salary_df.tail(5)

salary_df['Gender'].unique()

salary_df['Education Level'].unique()

salary_df['Job Title'].unique()

salary_df['Job Title'].value_counts()

"""**Label encoding**

"""

from sklearn.preprocessing import LabelEncoder

encoding=LabelEncoder()
# Encode labels in column 'species'.
salary_df['Gender']= encoding.fit_transform(salary_df['Gender'])
salary_df['Gender'].unique()
salary_df['Education Level']=encoding.fit_transform(salary_df['Education Level'])
salary_df['Job Title']=encoding.fit_transform(salary_df['Job Title'])

salary_df['Education Level'].unique()

salary_df['Job Title'].unique()

salary_df['Years of Experience'].unique()

"""**Missing values Handling**
dropna()
fillna() using mean,median(),mode().iloc[0] **bold text**

"""

#  Mean, Median, and Mode Imputation
mean_imputation_age = salary_df['Age'].fillna(salary_df['Age'].mean())
mean_imputation_gender = salary_df['Gender'].fillna(salary_df['Gender'].mean())
mean_imputation_edulev = salary_df['Education Level'].fillna(salary_df['Education Level'].mean())
mean_imputation_jobtit = salary_df['Job Title'].fillna(salary_df['Job Title'].mean())
mean_imputation_yrsexp = salary_df['Years of Experience'].fillna(salary_df['Years of Experience'].mean())
mean_imputation_sal = salary_df['Salary'].fillna(salary_df['Salary'].mean())
mean_imputation_yoexp = salary_df['Years of Experience'].fillna(salary_df['Years of Experience'].mean())

mean_imputation_yoexp

print(mean_imputation_yoexp)

print(mean_imputation_age)

print(salary_df)

"""iloc[:, :-1] means that you are selecting all the rows (:) and all the columns except the last one (:-1). This is used to select all the features (input variables) of the dataset.
.values converts the selected portion into a NumPy array, which is often required for machine learning algorithms.
Therefore, X represents the feature matrix (inputs), excluding the last column.
**bold text**
"""

X=salary_df.iloc[:,:-1].values
Y=salary_df.iloc[:,-1].values

print(X)

print(Y)

X=salary_df.drop(['Salary'],axis=1)
Y=salary_df['Salary']

#splitting the dataset in to training and testing
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

"""**For simple linear Regression, we will not use Feature Scaling**

For simple linear Regression, we will not use Feature Scaling
"""

#salary_df.head(20)

"""**Linear Regression ALGM**"""

from sklearn.linear_model import LinearRegression

"""to handle missing values (NaN values) in a dataset by replacing them with a specific value (in this case, the mean of each column). Let's break it down:

1. from sklearn.impute import SimpleImputer:
This imports the SimpleImputer class from the sklearn.impute module in the scikit-learn library. The SimpleImputer is used for handling missing values in a dataset.
2. imputer = SimpleImputer(strategy='mean'):
This creates an instance of the SimpleImputer class and specifies the imputation strategy. In this case, the strategy is 'mean', which means that any missing values (NaN) in the dataset will be replaced by the mean of the corresponding column.
**bold text**

X_train = imputer.fit_transform(X_train):
fit_transform(): This method combines two steps:
fit(): It computes the mean (or the specified statistic, like median) for each column in X_train where missing values are found.
transform(): It replaces the missing values in X_train with the computed mean.
This results in X_train being transformed, where all NaN values are replaced with the column means.
**bold text**
"""

from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')  # You can use 'median', 'most_frequent', or a custom value
X_train = imputer.fit_transform(X_train)

X_train

Y_train = Y_train.values.reshape(-1, 1)  # Reshape Y_train to a 2D array
Y_train = imputer.fit_transform(Y_train)
Y_train = Y_train.ravel()  # Flatten it back to a 1D array after imputation

#X_train = imputer.fit_transform(X_train)

# Assuming you already imputed X_train and Y_train
imputer = SimpleImputer(strategy='mean')  # Use the same imputer
X_test = imputer.fit_transform(X_test)

salary_lr=LinearRegression()
salary_lr.fit(X_train,Y_train)
salary_pred=salary_lr.predict(X_test)
print(salary_pred)

from sklearn.metrics import mean_squared_error

# Impute missing values in Y_test
Y_test = Y_test.reshape(-1, 1)  # Reshape Y_test to 2D (if it's not already)
Y_test = imputer.transform(Y_test).ravel()  # Impute and flatten it back to 1D

# Now, calculate MSE and RMSE
mse = mean_squared_error(Y_test, salary_pred)
rmse = np.sqrt(mse)

print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

# Plot Predictions vs Actual values
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, salary_pred, color='blue', label='Predicted vs Actual')
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', label='Ideal Fit Line')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs Actual Salary Values')
plt.legend()
plt.grid(True)
plt.show()

# Now, calculate MSE and RMSE
mse = mean_squared_error(Y_test, salary_pred)
rmse = np.sqrt(mse)

print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

# Plot Predictions vs Actual values
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, salary_pred, color='blue', label='Predicted vs Actual')
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', label='Ideal Fit Line')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs Actual Salary Values')
plt.legend()
plt.grid(True)
plt.show()